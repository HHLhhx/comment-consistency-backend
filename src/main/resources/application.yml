# 应用服务器配置
server:
  port: 8080
  servlet:
    context-path: /api

# Spring Boot 应用配置
spring:
  application:
    name: comment-backend
  ai:
    vectorstore:
      milvus:
        client:
          host: "localhost"
          port: 19530
        databaseName: "test"
        collectionName: "vector_store_test"
        initialize-schema: true
        embeddingDimension: 1024
        indexType: IVF_FLAT
        metricType: COSINE
        auto-id: true
        embedding-field-name: "vector"
        content-field-name: "content"

# 监控配置
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always
      probes:
        enabled: true
  prometheus:
    metrics:
      export:
        enabled: true
  metrics:
    distribution:
      percentiles-histogram:
        http.server.requests: true

# 日志配置
logging:
  level:
    root: INFO
    com.nju.comment.backend: DEBUG
    org.springframework.ai: INFO
    org.springframework.web: INFO
    org.springframework.cache: DEBUG
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/comment.log

# 应用配置
app:
  thread-pool:
    llm-pool:
      core-size: 20
      max-size: 50
      queue-capacity: 1000
      keep-alive: 60
      thread-name-prefix: llm-executor-
  ai:
    llm:
      timeout-ms: 1000
    ollama:
      chat:
        base-url: https://ollama.com
        api-key: ${OLLAMA_API_KEY:}
      embedding:
        base-url: http://localhost:11434
        model: "qwen3-embedding:0.6b"
        enable: false
  cache:
    comment:
      max-size: 500
      ttl: 3600
    modelsList:
      max-size: 100
      ttl: 60
