server:
  port: 8080
  servlet:
    context-path: /comment

spring:
  application:
    name: comment-backend

  cache:
    type: caffeine
    caffeine:
      spec: maximumSize=500,expireAfterAccess=600s

  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        model: codellama:7b

task:
  execution:
    pool:
      llm-task-executor:
        core-size: 20
        max-size: 50
        queue-capacity: 1000
        keep-alive: 60
        thread-name-prefix: llm-executor-
      health-check-executor:
        core-size: 2
        max-size: 5
        queue-capacity: 100
        keep-alive: 30
        thread-name-prefix: health-check-


management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always
      probes:
        enabled: true
  prometheus:
    metrics:
      export:
        enabled: true
  metrics:
    distribution:
      percentiles-histogram:
        http.server.requests: true

logging:
  level:
    root: INFO
    com.nju.comment.backend: DEBUG
    org.springframework.ai: INFO
    org.springframework.web: INFO
    org.springframework.cache: DEBUG
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/comment.log