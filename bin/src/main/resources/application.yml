# 应用服务器配置
server:
  port: 8080
  servlet:
    context-path: /api

# Spring Boot 应用配置
spring:
  application:
    name: comment-backend
  cache:
    type: caffeine
    caffeine:
      spec: maximumSize=500,expireAfterWrite=1h
  ai:
    ollama:
      base-url: https://ollama.com
      api-key: ${OLLAMA_API_KEY:}
      chat:
        options:
          temperature: 0.2
          top-p: 0.9
          top-k: 40

# 监控配置
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always
      probes:
        enabled: true
  prometheus:
    metrics:
      export:
        enabled: true
  metrics:
    distribution:
      percentiles-histogram:
        http.server.requests: true

# 日志配置
logging:
  level:
    root: INFO
    com.nju.comment.backend: DEBUG
    org.springframework.ai: INFO
    org.springframework.web: INFO
    org.springframework.cache: DEBUG
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/comment.log

# 应用配置
app:
  thread-pool:
    llm-pool:
      core-size: 20
      max-size: 50
      queue-capacity: 1000
      keep-alive: 60
      thread-name-prefix: llm-executor-
  cache:
    comment:
      max-size: 500
      ttl: 3600
    modelsList:
      max-size: 100
      ttl: 60